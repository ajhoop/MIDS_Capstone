{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "systematic-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (0.16)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.3.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.56.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: bert in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
      "Requirement already satisfied: erlastic in /usr/local/lib/python3.8/dist-packages (from bert) (2.0.0)\n",
      "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.8/dist-packages (1.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from bert-tensorflow) (1.15.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.4.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.8/dist-packages (from keras) (1.6.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from h5py->keras) (1.15.0)\n",
      "Requirement already satisfied: dask_ml in /usr/local/lib/python3.8/dist-packages (1.8.0)\n",
      "Requirement already satisfied: distributed>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from dask_ml) (2021.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from dask_ml) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from dask_ml) (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in /usr/local/lib/python3.8/dist-packages (from dask_ml) (0.24.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from dask_ml) (20.9)\n",
      "Requirement already satisfied: dask-glm>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from dask_ml) (0.2.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from dask_ml) (1.6.1)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from dask_ml) (0.52.0)\n",
      "Requirement already satisfied: multipledispatch>=0.4.9 in /usr/local/lib/python3.8/dist-packages (from dask_ml) (0.6.0)\n",
      "Requirement already satisfied: dask[array,dataframe]>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from dask_ml) (2021.2.0)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from dask-glm>=0.2.0->dask_ml) (1.6.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (5.4.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.8.7)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (1.1.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.11.1)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2.4.0->dask_ml) (6.1)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2.4.0->dask_ml) (2.3.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2.4.0->dask_ml) (1.7.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2.4.0->dask_ml) (2.0.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2.4.0->dask_ml) (1.0.2)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2.4.0->dask_ml) (5.8.0)\n",
      "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.8/dist-packages (from distributed>=2.4.0->dask_ml) (7.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from distributed>=2.4.0->dask_ml) (45.2.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from multipledispatch>=0.4.9->dask_ml) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.2->dask_ml) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.2->dask_ml) (2021.1)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.8/dist-packages (from partd>=0.3.10->dask[array,dataframe]>=2.4.0->dask_ml) (0.2.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.23->dask_ml) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.23->dask_ml) (2.1.0)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed>=2.4.0->dask_ml) (1.0.1)\n",
      "Requirement already satisfied: llvmlite<0.36,>=0.35.0 in /usr/local/lib/python3.8/dist-packages (from numba->dask_ml) (0.35.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->dask_ml) (2.4.7)\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.8/dist-packages (1.3.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.6.1)\n",
      "Requirement already satisfied: datascroller in /usr/local/lib/python3.8/dist-packages (1.4.1)\n",
      "Requirement already satisfied: pandasql in /usr/local/lib/python3.8/dist-packages (from datascroller) (0.7.3)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (from datascroller) (3.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datascroller) (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datascroller) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datascroller) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from pandas->datascroller) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datascroller) (1.15.0)\n",
      "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.8/dist-packages (from pandasql->datascroller) (1.3.23)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.4.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.15.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.4->tensorflow) (45.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz\n",
    "!pip install transformers\n",
    "!pip install bert\n",
    "!pip install bert-tensorflow\n",
    "!pip install keras\n",
    "!pip install dask_ml\n",
    "!pip install xgboost\n",
    "!pip install datascroller\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "rental-speed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "valid-japanese",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "# Import dask packages\n",
    "# import dask.dataframe as ddf\n",
    "from math import nan\n",
    "import panel as pn\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "from dask.delayed import delayed\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from dask_ml.model_selection import train_test_split\n",
    "import graphviz\n",
    "from datascroller import scroll\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "# text processing libraries\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "import transformers as ppb\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "from csv import reader\n",
    "\n",
    "import bert\n",
    "# from bert import run_classifier\n",
    "# from bert import optimization\n",
    "from bert import tokenization\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow import keras\n",
    "#### if use tensorflow=2.0.0, then import tensorflow.keras.model_selection \n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-eating",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Install BERT and BERT Tokenizer from the HuggingFace Transformers library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-tissue",
   "metadata": {},
   "source": [
    "We can easily switch between variants of BERT by changing out which model we import from HuggingFace; the rest of the code just flows unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.TFDistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.TFBertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "## For BERT Large, use this:\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.AutoModelWithLMHead, ppb.AutoTokenizer, 'bert-large-uncased')\n",
    "# from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "# For ROBERTa base model, use this:\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.TFRobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-individual",
   "metadata": {},
   "source": [
    "## Let's do an initial import on the sample dataset Padma created for HS4 codes 8712 and 8714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "meaningful-brook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_by_chapter\n",
      "sample_ignore_multiple_hscode_87128714.parq\n",
      "sample_ignore_multiple_hscode_chap39_40.parq\n"
     ]
    }
   ],
   "source": [
    "!ls /data/common/trade_data/2019_updated/data_samples_ignore_multiple_hscode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caroline-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first sample\n",
    "# import_df = dd.read_parquet('/data/common/trade_data/2019/data_samples/sample_87128714.parq', engine='fastparquet', chunksize=\"100MB\")\n",
    "\n",
    "# updated sample with the multple hs codes entries removed\n",
    "# import_df = dd.read_parquet('/data/common/trade_data/2019_updated/data_samples_ignore_multiple_hscode/sample_ignore_multiple_hscode_chap39_40.parq', engine='fastparquet', chunksize=\"100MB\")\n",
    "\n",
    "import_df = pd.read_parquet('/data/common/trade_data/2019_updated/data_samples_ignore_multiple_hscode/sample_ignore_multiple_hscode_chap39_40.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "traditional-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['System Identity Id', 'Estimate Arrival Date', 'Actual Arrival Date',\n",
       "       'Bill of Lading', 'Master Bill of Lading', 'Bill Type Code',\n",
       "       'Carrier SASC Code', 'Vessel Country Code', 'Vessel Code',\n",
       "       'Vessel Name', 'Voyage', 'Inbond Type', 'Manifest No',\n",
       "       'Mode of Transportation', 'Loading Port', 'Last Vist Foreign Port',\n",
       "       'US Clearing District', 'Unloading Port', 'Place of Receipt', 'Country',\n",
       "       'Country Sure Level', 'Weight in KG', 'Weight', 'Weight Unit', 'TEU',\n",
       "       'Quantity', 'Quantity Unit', 'Measure in CM', 'Measure', 'Measure Unit',\n",
       "       'Container Id', 'Container Size', 'Container Type',\n",
       "       'Container Desc Code', 'Container Load Status',\n",
       "       'Container Type of Service', 'Shipper Name', 'Shipper Address ',\n",
       "       'Raw Shipper Name', 'Raw Shipper Addr1', 'Raw Shipper Addr2',\n",
       "       'Raw Shipper Addr3', 'Raw Shipper Addr4', 'Raw Shipper Addr Others',\n",
       "       'Consignee Name', 'Consignee Address ', 'Raw Consignee Name',\n",
       "       'Raw Consignee Addr1', 'Raw Consignee Addr2', 'Raw Consignee Addr3',\n",
       "       'Raw Consignee Addr4', 'Raw Consignee Addr Others', 'Notify Party Name',\n",
       "       'Notify Party Address ', 'Raw Notify Party Name',\n",
       "       'Raw Notify Party Addr1', 'Raw Notify Party Addr2',\n",
       "       'Raw Notify Party Addr3', 'Raw Notify Party Addr4',\n",
       "       'Raw Notify Party Addr Others', 'Product Desc', 'Marks & Numbers',\n",
       "       'HS Code', 'HS Code Sure Level', 'CIF', 'Indicator of true supplier',\n",
       "       'Indicator of true buyer', 'END', 'Cleaned_HS_Code', 'HS_Code',\n",
       "       'Merged_Description', 'HS2 Chapter', 'HS4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "whole-exclusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System Identity Id</th>\n",
       "      <th>Estimate Arrival Date</th>\n",
       "      <th>Actual Arrival Date</th>\n",
       "      <th>Bill of Lading</th>\n",
       "      <th>Master Bill of Lading</th>\n",
       "      <th>Bill Type Code</th>\n",
       "      <th>Carrier SASC Code</th>\n",
       "      <th>Vessel Country Code</th>\n",
       "      <th>Vessel Code</th>\n",
       "      <th>Vessel Name</th>\n",
       "      <th>...</th>\n",
       "      <th>HS Code Sure Level</th>\n",
       "      <th>CIF</th>\n",
       "      <th>Indicator of true supplier</th>\n",
       "      <th>Indicator of true buyer</th>\n",
       "      <th>END</th>\n",
       "      <th>Cleaned_HS_Code</th>\n",
       "      <th>HS_Code</th>\n",
       "      <th>Merged_Description</th>\n",
       "      <th>HS2 Chapter</th>\n",
       "      <th>HS4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8191698</th>\n",
       "      <td>6003201905010000485147</td>\n",
       "      <td>20190429</td>\n",
       "      <td>20190429</td>\n",
       "      <td>SUDU29297AGIX154</td>\n",
       "      <td>None</td>\n",
       "      <td>R</td>\n",
       "      <td>SUDU, SUD HAMBURG/COLUMBUS LINE</td>\n",
       "      <td>SG</td>\n",
       "      <td>9283239</td>\n",
       "      <td>MONTE VERDE</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1009800.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>END</td>\n",
       "      <td>390110</td>\n",
       "      <td>390110</td>\n",
       "      <td>Polymers of ethylene, in primary forms ;Polyethylene having a specific gravity of less than 0.94 ;Having a relative viscosity of 1.44 or more;Other;Linear low density polyethylene;Low density polyethylene, except linear low density polyethylene;Medium density polyethylene</td>\n",
       "      <td>39</td>\n",
       "      <td>3901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021902</th>\n",
       "      <td>6003201904150000515332</td>\n",
       "      <td>20190412</td>\n",
       "      <td>20190412</td>\n",
       "      <td>CMDULHV2002586</td>\n",
       "      <td>None</td>\n",
       "      <td>R</td>\n",
       "      <td>CMDU, COMPAGNIE MARITIME DAFFRETEMEN</td>\n",
       "      <td>GB</td>\n",
       "      <td>9317975</td>\n",
       "      <td>CMA CGM WHITE SHARK</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>END</td>\n",
       "      <td>390110</td>\n",
       "      <td>390110</td>\n",
       "      <td>Polymers of ethylene, in primary forms ;Polyethylene having a specific gravity of less than 0.94 ;Having a relative viscosity of 1.44 or more;Other;Linear low density polyethylene;Low density polyethylene, except linear low density polyethylene;Medium density polyethylene</td>\n",
       "      <td>39</td>\n",
       "      <td>3901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             System Identity Id Estimate Arrival Date Actual Arrival Date  \\\n",
       "8191698  6003201905010000485147  20190429              20190429             \n",
       "8021902  6003201904150000515332  20190412              20190412             \n",
       "\n",
       "           Bill of Lading Master Bill of Lading Bill Type Code  \\\n",
       "8191698  SUDU29297AGIX154  None                  R               \n",
       "8021902  CMDULHV2002586    None                  R               \n",
       "\n",
       "                            Carrier SASC Code Vessel Country Code Vessel Code  \\\n",
       "8191698  SUDU, SUD HAMBURG/COLUMBUS LINE       SG                  9283239      \n",
       "8021902  CMDU, COMPAGNIE MARITIME DAFFRETEMEN  GB                  9317975      \n",
       "\n",
       "                 Vessel Name  ... HS Code Sure Level        CIF  \\\n",
       "8191698  MONTE VERDE          ...  8                  1009800.0   \n",
       "8021902  CMA CGM WHITE SHARK  ...  8                  0.0         \n",
       "\n",
       "        Indicator of true supplier Indicator of true buyer  END  \\\n",
       "8191698  Y                          Y                       END   \n",
       "8021902  Y                          Y                       END   \n",
       "\n",
       "        Cleaned_HS_Code HS_Code  \\\n",
       "8191698  390110          390110   \n",
       "8021902  390110          390110   \n",
       "\n",
       "                                                                                                                                                                                                                                                                       Merged_Description  \\\n",
       "8191698  Polymers of ethylene, in primary forms ;Polyethylene having a specific gravity of less than 0.94 ;Having a relative viscosity of 1.44 or more;Other;Linear low density polyethylene;Low density polyethylene, except linear low density polyethylene;Medium density polyethylene   \n",
       "8021902  Polymers of ethylene, in primary forms ;Polyethylene having a specific gravity of less than 0.94 ;Having a relative viscosity of 1.44 or more;Other;Linear low density polyethylene;Low density polyethylene, except linear low density polyethylene;Medium density polyethylene   \n",
       "\n",
       "        HS2 Chapter   HS4  \n",
       "8191698  39          3901  \n",
       "8021902  39          3901  \n",
       "\n",
       "[2 rows x 73 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't truncate text fields in the display\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "\n",
    "import_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "engaging-sacramento",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134035"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(import_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "multiple-louis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      Desc  HSCode\n",
      "8191698  CONTENIENDO 24.75 MTLDF2023S1 LOW DENSITY POLY...  390110\n",
      "8021902  FREIGHT PAYABLT AT LE HAVRE ROTOMOLDING LINEAR...  390110\n",
      "134035\n"
     ]
    }
   ],
   "source": [
    "df1 = import_df[['Product Desc', 'Cleaned_HS_Code']]\n",
    "df1.columns = ['Desc', 'HSCode']\n",
    "print(df1.head(2))\n",
    "print(len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "southern-stranger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         HSCode                                               Desc\n",
      "8191698  390110  Polymers of ethylene, in primary forms ;Polyet...\n",
      "1848406  390120  Polymers of ethylene, in primary forms ;Polyet...\n",
      "209\n"
     ]
    }
   ],
   "source": [
    "hs_code_desc = import_df[['Cleaned_HS_Code', 'Merged_Description']]\n",
    "hs_code_desc = hs_code_desc.drop_duplicates()\n",
    "hs_code_desc.columns = ['HSCode', 'Desc']\n",
    "print(hs_code_desc.head(2))\n",
    "print(len(hs_code_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specialized-portrait",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134244"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.append(hs_code_desc[['Desc', 'HSCode']]).reset_index()\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframes back to pandas\n",
    "\n",
    "# df1_pd = df1.compute()\n",
    "# len(df1_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "latest-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_pd = df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-dance",
   "metadata": {},
   "source": [
    "Remove long number sequences (that potentially contain HS Codes) from the descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lesbian-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_pd['Desc'] = [re.sub('\\d{4,}', '', x) for x in df1_pd['Desc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-newfoundland",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Let's tokenize the description fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-discussion",
   "metadata": {},
   "source": [
    "#### Create embeddings with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(data, column_name):\n",
    "#     '''\n",
    "#     Tokenize text\n",
    "#     '''\n",
    "#     tokens = data[column_name].apply((lambda x: nltk.word_tokenize(x)))\n",
    "    \n",
    "#     data['NLTK'+column_name] = np.array(tokens)\n",
    "    \n",
    "#     return data\n",
    "# #     return list(\n",
    "# #         filter(lambda word: word.isalnum(), tokens)\n",
    "# #     )\n",
    "\n",
    "# stop_words = stopwords.words(\"english\")\n",
    "\n",
    "# def remove_stopwords(words):\n",
    "#     '''\n",
    "#     Remove stop words from the list of words\n",
    "#     '''\n",
    "    \n",
    "#     filtered = filter(lambda word: word not in stop_words, words)\n",
    "    \n",
    "#     return list(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-bottom",
   "metadata": {},
   "source": [
    "#### Create embeddings with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pre_process(data, column_name, max_length):\n",
    "#     \"\"\"\n",
    "#     Function takes inputs:\n",
    "#     - data in the form of a pandas dataframe\n",
    "#     - column_name containing the text to be embedded\n",
    "#     - max length\n",
    "#     and produces as output the input data BERT requires as an array consisting of:\n",
    "#     - Sentence IDs padded to the max length\n",
    "#     - BERT Masks that tell BERT which of the Sentence IDs are 0 and should be ignored\n",
    "#     - SequenceIDs which are all 0 for our classification task\n",
    "#     \"\"\"\n",
    "#     # Tokenize each item and add the special beginning/end tokens\n",
    "#     tokenized = data[column_name].apply((lambda x: tokenizer.encode(x, add_special_tokens=False, max_length=max_length, truncation=True)))\n",
    "#     data['BERT_'+column_name] = np.array(tokenized)\n",
    "# #     data['BERT_'+column_name] = tokenized\n",
    "      \n",
    "# #     # Create the padding based on the max length so all are same shape\n",
    "# #     bertSentenceIDs = np.array([i + [0]*(max_length-len(i)) for i in tokenized.values])\n",
    "    \n",
    "# #     # Create the attention mask so BERT knows which contain values and which are 0s that should be ignored\n",
    "# #     bertMasks = np.where(bertSentenceIDs != 0, 1, 0)\n",
    "\n",
    "# #     # Create the BERT sequence IDs. In this case they are all 0 since it's the same sentence input.\n",
    "# #     bertSequenceIDs = np.array([np.zeros(max_length) for i in tokenized.values], dtype=int)\n",
    "    \n",
    "# #     # Create and return the data array containing both the padded and the attention mask\n",
    "# #     X_data = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])\n",
    "\n",
    "# #     # Also look at the vocabulary size in the tokenizer\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-cargo",
   "metadata": {},
   "source": [
    "In the past we have run into memory issues depending on the length of the input, so we set up a variable to truncate the tokens being input for each record.\n",
    "\n",
    "First, let's check the max length of the different tokenized columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length_lst = ['Product Desc', 'Merged_Description']\n",
    "\n",
    "# max_length_dict = {}\n",
    "\n",
    "# for l in length_lst:\n",
    "#     tokenized = []\n",
    "#     tokenized = import_df_pd[l].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "#     # Find the max length for the tokenized examples\n",
    "#     max_length = 0\n",
    "#     for i in tokenized.values:\n",
    "#         if len(i) > max_length:\n",
    "#             max_length = len(i)\n",
    "            \n",
    "\n",
    "#     print('Max length of column', l, max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-eating",
   "metadata": {},
   "source": [
    "This could be a problem if we have very, very short entries in the description fields.\n",
    "\n",
    "Some possible solutions:\n",
    "1. Augment each entry with the dictionary definition.\n",
    "2. Add extra training records of just the dictionary definition.\n",
    "3. Train on only the dictionary definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-cleveland",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Encode the description fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = 180\n",
    "\n",
    "# # Create BERT embeddings for Product Desc and Merged_Description, append to pandas dataframe\n",
    "# X_pd = pre_process(df1_pd, 'Desc', max_length)\n",
    "\n",
    "\n",
    "\n",
    "# # Create NLTK embeddings for Product Desc and Merged_Description, append to pandas dataframe\n",
    "# X_pd = tokenize(X_pd, 'Desc')\n",
    "\n",
    "# X_pd.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-battle",
   "metadata": {},
   "source": [
    "### Create train, dev, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "excited-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pd = df1_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baking-ordering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pd = X_pd['HSCode']\n",
    "type(y_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceramic-subcommittee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train set is 107395\n",
      "Size of the dev set is 26849\n",
      "Size of the test set is 26849\n",
      "Size of the train label set is 107395\n",
      "Size of the dev label set is 26849\n",
      "Size of the test label set is 26849\n"
     ]
    }
   ],
   "source": [
    "# X = X_pd['Desc']\n",
    "y = X_pd['HSCode']\n",
    "\n",
    "# Split once to create the test set\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_pd, y, test_size=0.2, random_state=91)\n",
    "\n",
    "# Re-split the train set to create a dev set\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_pd, y, test_size=0.2, random_state=91, stratify=y)\n",
    "\n",
    "print('Size of the train set is', len(X_train))\n",
    "print('Size of the dev set is', len(X_dev))\n",
    "print('Size of the test set is', len(X_test))\n",
    "print('Size of the train label set is', len(y_train))\n",
    "print('Size of the dev label set is', len(y_dev))\n",
    "print('Size of the test label set is', len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "beautiful-pattern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Desc</th>\n",
       "      <th>HSCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57017</th>\n",
       "      <td>57017</td>\n",
       "      <td>12 PACKAGES WITH 144ROLLS ROLLS OF CELLULAR PVC FILM COMBINED WITH TEXTILE MATERIALS. REF: GREEN VINYL NET WEIGHT: .35KGS P.A &lt;br/&gt;</td>\n",
       "      <td>392049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37332</th>\n",
       "      <td>37332</td>\n",
       "      <td>RUBBER CHEMICAL DIOTOLYLGUANIDINE DOTG PDR-D .&lt;br/&gt;</td>\n",
       "      <td>391390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  \\\n",
       "57017  57017   \n",
       "37332  37332   \n",
       "\n",
       "                                                                                                                                      Desc  \\\n",
       "57017  12 PACKAGES WITH 144ROLLS ROLLS OF CELLULAR PVC FILM COMBINED WITH TEXTILE MATERIALS. REF: GREEN VINYL NET WEIGHT: .35KGS P.A <br/>   \n",
       "37332  RUBBER CHEMICAL DIOTOLYLGUANIDINE DOTG PDR-D .<br/>                                                                                   \n",
       "\n",
       "       HSCode  \n",
       "57017  392049  \n",
       "37332  391390  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "devoted-disorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Desc</th>\n",
       "      <th>HSCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28997</th>\n",
       "      <td>2113176</td>\n",
       "      <td>ION EXCHANGE RESINS PO &lt;br/&gt;</td>\n",
       "      <td>390910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128828</th>\n",
       "      <td>6885399</td>\n",
       "      <td>NBR VULCANIZED CELLULAR NBR RUBBER PO#: HS CODE:.10. THIS SHIPMENT CONTAINS NO SOLID WOOD PACKING MATERIALS.&lt;br/&gt;</td>\n",
       "      <td>401610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  \\\n",
       "28997   2113176   \n",
       "128828  6885399   \n",
       "\n",
       "                                                                                                                     Desc  \\\n",
       "28997   ION EXCHANGE RESINS PO <br/>                                                                                        \n",
       "128828  NBR VULCANIZED CELLULAR NBR RUBBER PO#: HS CODE:.10. THIS SHIPMENT CONTAINS NO SOLID WOOD PACKING MATERIALS.<br/>   \n",
       "\n",
       "        HSCode  \n",
       "28997   390910  \n",
       "128828  401610  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-soldier",
   "metadata": {},
   "source": [
    "## Create baseline of predicting the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "immune-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when predicting majority class  0.0074584477862097865\n"
     ]
    }
   ],
   "source": [
    "counts = X_train['HSCode'].value_counts().to_dict()\n",
    "# print(counts)\n",
    "max_value = max(counts.values())\n",
    "print('Accuracy when predicting majority class ', max_value/len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-harvest",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Construct a Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-pixel",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Use BOW on the words in the Product Desc column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer()\n",
    "\n",
    "# fit_transform() creates dictionary and return term-document matrix.\n",
    "X_train_counts = count_vector.fit_transform(X_train['Desc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = MultinomialNB().fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_counts = count_vector.transform(X_dev['Desc'])\n",
    "# X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "# Execute prediction(classification).\n",
    "predicted = clf1.predict(X_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score:', f1_score(y_dev, predicted, average=\"macro\"))\n",
    "print('Precision:', precision_score(y_dev, predicted, average=\"macro\"))\n",
    "print('Recall:', recall_score(y_dev, predicted, average=\"macro\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "plot_confusion_matrix(clf1, X_new_counts, y_dev)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-testament",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "religious-nightlife",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Use TF-IDF on the words in the Product Desc column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# fit_transform() creates dictionary and return term-document matrix.\n",
    "X_train_counts = count_vector.fit_transform(X_train['Desc'])\n",
    "\n",
    "# Import TfidfTransformer class.\n",
    "# TfidfTransformer transoforms count matrix to tf-idf representation.\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# fit_transform transforms count matrix to tf-idf representation(vector).\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model(naive bayes) and training. \n",
    "\n",
    "clf2 = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions\n",
    "# Transfroming.\n",
    "X_new_counts = count_vector.transform(X_dev['Desc'])\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "# Execute prediction(classification).\n",
    "predicted = clf2.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score:', f1_score(y_dev, predicted, average=\"macro\"))\n",
    "print('Precision:', precision_score(y_dev, predicted, average=\"macro\"))\n",
    "print('Recall:', recall_score(y_dev, predicted, average=\"macro\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_dev, predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "plot_confusion_matrix(clf2, X_new_tfidf, y_dev)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-coordinate",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Use BOW on the Merged Description field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform() creates dictionary and return term-document matrix.\n",
    "X_train_counts = count_vector.fit_transform(X_train['Merged_Description'])\n",
    "\n",
    "# # Import TfidfTransformer class.\n",
    "# # TfidfTransformer transoforms count matrix to tf-idf representation.\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# # fit_transform transforms count matrix to tf-idf representation(vector).\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model(naive bayes) and training. \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf3 = MultinomialNB().fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions\n",
    "# Transfroming.\n",
    "X_new_counts = count_vector.transform(X_dev['Merged_Description'])\n",
    "# X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "# Execute prediction(classification).\n",
    "predicted = clf3.predict(X_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score:', f1_score(y_dev, predicted, average=\"macro\"))\n",
    "print('Precision:', precision_score(y_dev, predicted, average=\"macro\"))\n",
    "print('Recall:', recall_score(y_dev, predicted, average=\"macro\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "plot_confusion_matrix(clf3, X_new_counts, y_dev)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-height",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Use TF-IDF on the Merged Description field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform() creates dictionary and return term-document matrix.\n",
    "X_train_counts = count_vector.fit_transform(X_train['Merged_Description'])\n",
    "\n",
    "# Import TfidfTransformer class.\n",
    "# TfidfTransformer transoforms count matrix to tf-idf representation.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# fit_transform transforms count matrix to tf-idf representation(vector).\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model(naive bayes) and training. \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf2 = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions\n",
    "# Transfroming.\n",
    "X_new_counts = count_vector.transform(X_dev['Merged_Description'])\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "# Execute prediction(classification).\n",
    "predicted = clf2.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score:', f1_score(y_dev, predicted, average=\"macro\"))\n",
    "print('Precision:', precision_score(y_dev, predicted, average=\"macro\"))\n",
    "print('Recall:', recall_score(y_dev, predicted, average=\"macro\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "plot_confusion_matrix(clf2, X_new_tfidf, y_dev)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_dev, predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-superintendent",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Use the BERT embeddings in the Product Desc column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the embedding column from list to string\n",
    "X_train['BERTProduct Desc'] = X_train['BERTProduct Desc'].apply(str).apply(', '.join)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer()\n",
    "\n",
    "# fit_transform() creates dictionary and return term-document matrix.\n",
    "X_train_counts = count_vector.fit_transform(X_train['Product Desc'])\n",
    "\n",
    "# Import TfidfTransformer class.\n",
    "# TfidfTransformer transoforms count matrix to tf-idf representation.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# fit_transform transforms count matrix to tf-idf representation(vector).\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model(naive bayes) and training. \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions\n",
    "# Transfroming.\n",
    "X_new_counts = count_vector.transform(X_dev['Product Desc'])\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "# Execute prediction(classification).\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score:', f1_score(y_dev, predicted, average=\"macro\"))\n",
    "print('Precision:', precision_score(y_dev, predicted, average=\"macro\"))\n",
    "print('Recall:', recall_score(y_dev, predicted, average=\"macro\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "plot_confusion_matrix(clf, X_new_tfidf, y_dev)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-evening",
   "metadata": {},
   "source": [
    "## Create functions to make model building easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "manual-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results = pd.DataFrame(index = ['Baseline', 'NB-BOW Desc','NB-tfidf Desc', 'KNN-BOW Desc', 'KNN-tfidf Desc', 'LogReg-BOW Desc', 'LogReg-tfidf Desc', \n",
    "                                'SVM-BOW Desc', 'SVM-tfidf Desc', 'XGBoost-BOW Desc', 'XGBoost-tfidf Desc', 'RF-BOW Desc', 'RF-tfidf Desc'],\n",
    "                       columns=['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "checked-mercy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB-BOW Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB-tfidf Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN-BOW Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN-tfidf Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg-BOW Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg-tfidf Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM-BOW Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM-tfidf Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost-BOW Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost-tfidf Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF-BOW Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF-tfidf Desc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy\n",
       "Baseline                NaN\n",
       "NB-BOW Desc             NaN\n",
       "NB-tfidf Desc           NaN\n",
       "KNN-BOW Desc            NaN\n",
       "KNN-tfidf Desc          NaN\n",
       "LogReg-BOW Desc         NaN\n",
       "LogReg-tfidf Desc       NaN\n",
       "SVM-BOW Desc            NaN\n",
       "SVM-tfidf Desc          NaN\n",
       "XGBoost-BOW Desc        NaN\n",
       "XGBoost-tfidf Desc      NaN\n",
       "RF-BOW Desc             NaN\n",
       "RF-tfidf Desc           NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reported-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.at['Baseline', 'Accuracy'] = max_value/len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-sheffield",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "freelance-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier, X, y, X_test, y_test, filename):\n",
    "    ### provide classifier, train and test set\n",
    "    ### get train/val split\n",
    "    ### fit on val\n",
    "    ### test on test\n",
    "    ### return accuracy score for test\n",
    "    tic = time()\n",
    "    mod = classifier.fit(X, y)\n",
    "    toc = time()\n",
    "    print(f\"Trained model in {toc - tic:0.4} seconds\")\n",
    "    \n",
    "    # save model parameters\n",
    "#     filename = classifier([('vectorizer')])+'_model.sav'\n",
    "    pickle.dump(mod, open(filename, 'wb'))\n",
    "    \n",
    "    print(\"Dev set results:\")\n",
    "    tic = time()\n",
    "    X_test_preds = mod.predict(X_test)\n",
    "    toc = time()\n",
    "    print(classification_report(y_test, X_test_preds) )\n",
    "    # plot confusion matrix\n",
    "#     plt.figure(figsize=(30,30))\n",
    "#     plot_confusion_matrix(mod, y_test, X_test_preds)\n",
    "#     plt.show()\n",
    "    # print confusion matrix\n",
    "    print(confusion_matrix(y_test, X_test_preds))\n",
    "    print(f\"Created predictions in {toc - tic:0.4} seconds\")\n",
    "    return accuracy_score(y_test,X_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial1 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    " \n",
    "acc = train(trial1, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/NB_BOW_model.sav')\n",
    "\n",
    "results.at['NB-BOW Desc','Accuracy'] = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial2 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    " \n",
    "acc = train(trial2, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/NB_tfidf_model.sav')\n",
    "\n",
    "results.at['NB-tfidf Desc','Accuracy'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial3 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('classifier', KNeighborsClassifier()),\n",
    "])\n",
    " \n",
    "acc = train(trial3, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/KNN_BOW_model.sav')\n",
    "\n",
    "results.at['KNN-BOW Desc','Accuracy'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial4 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "    ('classifier', KNeighborsClassifier()),\n",
    "])\n",
    " \n",
    "acc = train(trial4, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/KNN_tfidf_model.sav')\n",
    "\n",
    "results.at['KNN-tfidf Desc','Accuracy'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial5 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('classifier',LogisticRegression()),\n",
    "])\n",
    " \n",
    "acc = train(trial5, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/LogReg_BOW_model.sav')\n",
    "\n",
    "results.at['LogReg-BOW Desc','Accuracy'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial6 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "    ('classifier',LogisticRegression()),\n",
    "])\n",
    " \n",
    "acc = train(trial6, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/LogReg_tfidf_model.sav')\n",
    "\n",
    "results.at['LogReg-tfidf Desc','Accuracy'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial7 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('classifier', SVC()),\n",
    "])\n",
    " \n",
    "acc = train(trial7, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/SVM_BOW_model.sav')\n",
    "\n",
    "results.at['SVM-BOW Desc','Accuracy'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial8 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "    ('classifier', SVC()),\n",
    "])\n",
    " \n",
    "acc = train(trial8, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/SVM_tfidf_model.sav')\n",
    "\n",
    "results.at['SVM-tfidf Desc','Accuracy'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial9 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('classifier', XGBClassifier()),\n",
    "])\n",
    " \n",
    "acc = train(trial9, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/XGB_BOW_model.sav')\n",
    "\n",
    "results.at['XGBoost-BOW Desc','Accuracy'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial10 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "    ('classifier', XGBClassifier()),\n",
    "])\n",
    " \n",
    "acc = train(trial10, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/XGB_tfidf_model.sav')\n",
    "\n",
    "results.at['XGBoost-tfidf Desc','Accuracy'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "collect-democrat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 1.686e+03 seconds\n",
      "Dev set results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      390110       0.83      0.88      0.85       200\n",
      "      390120       0.90      0.86      0.88       200\n",
      "      390130       0.97      0.96      0.97       200\n",
      "      390140       0.93      0.96      0.94       181\n",
      "      390190       0.90      0.86      0.88       200\n",
      "      390210       0.88      0.84      0.86       200\n",
      "      390220       0.95      0.94      0.94        95\n",
      "      390230       0.85      0.89      0.87       200\n",
      "      390290       0.85      0.92      0.88       192\n",
      "      390311       0.99      0.99      0.99       200\n",
      "      390319       0.95      0.91      0.93        90\n",
      "      390320       0.94      0.98      0.96       200\n",
      "      390330       0.92      0.94      0.93       200\n",
      "      390390       0.87      0.85      0.86       200\n",
      "      390410       0.91      0.98      0.94       186\n",
      "      390421       0.93      0.87      0.90        46\n",
      "      390422       0.91      0.89      0.90        55\n",
      "      390430       0.93      0.94      0.94       163\n",
      "      390440       0.88      0.50      0.64        14\n",
      "      390450       0.97      0.97      0.97        34\n",
      "      390461       0.91      0.93      0.92       182\n",
      "      390469       0.86      0.87      0.86        91\n",
      "      390490       0.93      0.81      0.87        16\n",
      "      390512       0.88      0.71      0.79        21\n",
      "      390519       0.75      0.86      0.80        28\n",
      "      390521       1.00      0.82      0.90        17\n",
      "      390529       0.92      0.94      0.93       123\n",
      "      390530       0.91      0.95      0.93        61\n",
      "      390591       0.93      0.75      0.83        56\n",
      "      390599       0.69      0.81      0.75        47\n",
      "      390610       0.90      0.83      0.86        72\n",
      "      390690       0.73      0.73      0.73       200\n",
      "      390710       0.86      0.93      0.89       200\n",
      "      390720       0.86      0.82      0.84       200\n",
      "      390730       0.91      0.92      0.91       200\n",
      "      390740       0.88      0.92      0.90       200\n",
      "      390750       0.97      0.84      0.90        43\n",
      "      390761       0.97      0.98      0.97       186\n",
      "      390769       0.92      0.86      0.89        71\n",
      "      390770       1.00      0.50      0.67         4\n",
      "      390791       0.84      0.84      0.84        63\n",
      "      390799       0.84      0.78      0.81       200\n",
      "      390810       0.82      0.76      0.78       200\n",
      "      390890       0.77      0.87      0.82       200\n",
      "      390910       0.92      0.95      0.93       103\n",
      "      390920       0.62      0.50      0.55        32\n",
      "      390931       0.83      0.71      0.77        14\n",
      "      390939       0.56      0.83      0.67         6\n",
      "      390940       0.92      0.88      0.90       112\n",
      "      390950       0.70      0.81      0.75       200\n",
      "      391000       0.89      0.91      0.90       200\n",
      "      391110       0.97      0.97      0.97       135\n",
      "      391190       0.82      0.71      0.76       200\n",
      "      391211       0.86      1.00      0.92         6\n",
      "      391212       0.00      0.00      0.00         1\n",
      "      391220       0.92      0.99      0.95        70\n",
      "      391231       0.83      0.94      0.88       200\n",
      "      391239       0.97      0.96      0.96       200\n",
      "      391290       0.92      0.96      0.94       185\n",
      "      391310       0.96      0.88      0.92        26\n",
      "      391390       0.96      0.86      0.91        88\n",
      "      391400       0.87      0.95      0.91       150\n",
      "      391510       0.83      0.71      0.77        28\n",
      "      391520       0.91      0.91      0.91        11\n",
      "      391530       0.96      0.97      0.96       115\n",
      "      391590       0.82      0.93      0.87       200\n",
      "      391610       0.79      0.59      0.68        37\n",
      "      391620       0.83      0.82      0.82       200\n",
      "      391690       0.73      0.76      0.74       182\n",
      "      391710       0.93      0.95      0.94       123\n",
      "      391721       0.69      0.67      0.68        57\n",
      "      391722       0.88      0.95      0.92       200\n",
      "      391723       0.92      0.74      0.82        88\n",
      "      391729       0.69      0.59      0.64        91\n",
      "      391731       0.65      0.70      0.67       103\n",
      "      391732       0.69      0.68      0.68       200\n",
      "      391733       0.55      0.65      0.59        74\n",
      "      391739       0.66      0.67      0.67       200\n",
      "      391740       0.78      0.78      0.78       200\n",
      "      391810       0.90      0.94      0.92       200\n",
      "      391890       0.89      0.90      0.89       200\n",
      "      391910       0.80      0.74      0.77       200\n",
      "      391990       0.68      0.69      0.68       200\n",
      "      392010       0.76      0.74      0.75       200\n",
      "      392020       0.83      0.83      0.83       200\n",
      "      392030       0.80      0.93      0.86       200\n",
      "      392043       0.86      0.89      0.88       194\n",
      "      392049       0.83      0.83      0.83       174\n",
      "      392051       0.90      0.93      0.91       152\n",
      "      392059       0.87      0.77      0.82        44\n",
      "      392061       0.89      0.76      0.82        78\n",
      "      392062       0.84      0.86      0.85       200\n",
      "      392063       0.67      0.43      0.52        14\n",
      "      392069       0.88      0.69      0.78        55\n",
      "      392071       0.82      0.92      0.87        25\n",
      "      392073       0.91      0.67      0.77        15\n",
      "      392079       0.77      0.71      0.74        28\n",
      "      392091       0.98      0.96      0.97        67\n",
      "      392092       0.81      0.84      0.83        31\n",
      "      392093       0.67      0.67      0.67         3\n",
      "      392094       1.00      0.71      0.83         7\n",
      "      392099       0.83      0.74      0.78       141\n",
      "      392111       0.79      0.73      0.76        30\n",
      "      392112       0.94      0.86      0.90       200\n",
      "      392113       0.74      0.73      0.73       200\n",
      "      392114       0.70      0.95      0.80        78\n",
      "      392119       0.84      0.78      0.81       200\n",
      "      392190       0.80      0.69      0.75       200\n",
      "      392210       0.92      0.97      0.95       200\n",
      "      392220       0.73      0.87      0.80       200\n",
      "      392290       0.93      0.94      0.94       200\n",
      "      392310       0.69      0.76      0.72       200\n",
      "      392321       0.80      0.77      0.78       200\n",
      "      392329       0.67      0.78      0.72       200\n",
      "      392330       0.84      0.81      0.83       200\n",
      "      392340       0.83      0.89      0.86       200\n",
      "      392350       0.73      0.71      0.72       200\n",
      "      392390       0.64      0.66      0.65       200\n",
      "      392410       0.70      0.66      0.68       200\n",
      "      392490       0.74      0.56      0.63       200\n",
      "      392510       0.88      0.84      0.86        89\n",
      "      392520       0.86      0.85      0.86       200\n",
      "      392530       0.91      0.95      0.93       200\n",
      "      392590       0.88      0.77      0.82       200\n",
      "      392610       0.90      0.85      0.87       200\n",
      "      392620       0.82      0.78      0.80       200\n",
      "      392630       0.55      0.79      0.65       200\n",
      "      392640       0.71      0.70      0.71       200\n",
      "      392690       0.42      0.26      0.32       200\n",
      "      400110       0.94      0.91      0.93       122\n",
      "      400121       0.87      0.80      0.83       200\n",
      "      400122       0.91      0.86      0.89       200\n",
      "      400129       0.76      0.81      0.79        48\n",
      "      400130       1.00      1.00      1.00        13\n",
      "      400211       0.93      0.97      0.95        99\n",
      "      400219       0.92      0.94      0.93       200\n",
      "      400220       0.87      0.86      0.87       200\n",
      "      400231       0.83      0.75      0.79        20\n",
      "      400239       0.94      0.92      0.93        51\n",
      "      400241       0.96      0.97      0.97       190\n",
      "      400249       0.79      1.00      0.88        15\n",
      "      400251       0.92      0.98      0.95       200\n",
      "      400259       0.95      0.92      0.93        99\n",
      "      400260       0.97      0.96      0.96       157\n",
      "      400270       0.96      0.97      0.96       189\n",
      "      400280       0.83      0.48      0.61        21\n",
      "      400291       0.96      0.94      0.95       194\n",
      "      400299       0.81      0.64      0.72        53\n",
      "      400300       0.98      0.97      0.97       174\n",
      "      400400       0.96      0.91      0.94        57\n",
      "      400510       0.87      0.87      0.87       150\n",
      "      400520       0.80      0.89      0.84         9\n",
      "      400591       0.68      0.74      0.71        43\n",
      "      400599       0.94      0.89      0.91       117\n",
      "      400610       0.79      0.89      0.84       200\n",
      "      400690       0.80      0.42      0.55        19\n",
      "      400700       0.92      0.97      0.95       200\n",
      "      400811       0.72      0.81      0.76        69\n",
      "      400819       0.73      0.48      0.58        23\n",
      "      400821       0.77      0.81      0.79       139\n",
      "      400829       0.43      0.58      0.50        52\n",
      "      400911       0.65      0.47      0.55        59\n",
      "      400912       0.56      0.57      0.56        35\n",
      "      400921       0.81      0.89      0.84       200\n",
      "      400922       0.85      0.57      0.68        49\n",
      "      400931       0.75      0.64      0.69       182\n",
      "      400932       0.71      0.74      0.73        50\n",
      "      400941       0.88      0.91      0.89       161\n",
      "      400942       0.66      0.54      0.59        81\n",
      "      401011       0.82      0.79      0.81        29\n",
      "      401012       0.85      0.75      0.80       124\n",
      "      401019       0.93      0.93      0.93       200\n",
      "      401031       0.79      0.76      0.78        59\n",
      "      401032       0.83      0.53      0.64        36\n",
      "      401033       0.93      0.89      0.91        97\n",
      "      401034       0.89      0.77      0.83        31\n",
      "      401035       0.86      0.73      0.79        66\n",
      "      401036       0.86      0.75      0.80        24\n",
      "      401039       0.72      0.77      0.74       132\n",
      "      401110       0.81      0.81      0.81       200\n",
      "      401120       0.86      0.82      0.84       200\n",
      "      401130       0.96      0.96      0.96        72\n",
      "      401140       0.90      0.94      0.92       200\n",
      "      401150       0.75      0.92      0.83        36\n",
      "      401170       0.78      0.90      0.84       200\n",
      "      401180       0.83      0.77      0.79       200\n",
      "      401190       0.87      0.91      0.89       200\n",
      "      401211       0.93      0.89      0.91       100\n",
      "      401212       0.94      0.94      0.94       200\n",
      "      401213       0.94      0.93      0.94        55\n",
      "      401219       0.88      0.84      0.86        51\n",
      "      401220       0.95      0.91      0.93       200\n",
      "      401290       0.92      0.88      0.90       200\n",
      "      401310       0.91      0.90      0.91       115\n",
      "      401320       0.95      0.97      0.96       200\n",
      "      401390       0.91      0.88      0.89       176\n",
      "      401410       0.90      0.95      0.92        38\n",
      "      401490       1.00      0.74      0.85        31\n",
      "      401511       0.93      0.97      0.95       139\n",
      "      401519       0.90      0.93      0.91       200\n",
      "      401590       0.94      0.90      0.92       100\n",
      "      401610       0.72      0.88      0.79       200\n",
      "      401691       0.90      0.95      0.92       200\n",
      "      401692       0.94      0.99      0.96       135\n",
      "      401693       0.79      0.78      0.78       200\n",
      "      401694       0.75      0.60      0.67         5\n",
      "      401695       0.97      0.93      0.95       200\n",
      "      401699       0.69      0.54      0.61       200\n",
      "      401700       0.87      0.78      0.82        59\n",
      "\n",
      "    accuracy                           0.84     26849\n",
      "   macro avg       0.84      0.82      0.82     26849\n",
      "weighted avg       0.85      0.84      0.84     26849\n",
      "\n",
      "[[176  10   1 ...   0   1   0]\n",
      " [  9 172   0 ...   0   0   0]\n",
      " [  0   0 193 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 185   0   0]\n",
      " [  0   0   0 ...   0 108   2]\n",
      " [  0   0   0 ...   0   1  46]]\n",
      "Created predictions in 8.247 seconds\n"
     ]
    }
   ],
   "source": [
    "trial11 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('classifier', RandomForestClassifier()),\n",
    "])\n",
    " \n",
    "acc = train(trial11, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/RF_BOW_model.sav')\n",
    "\n",
    "results.at['RF-BOW Desc','Accuracy'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "quiet-intervention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 1.005e+03 seconds\n",
      "Dev set results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      390110       0.82      0.89      0.86       200\n",
      "      390120       0.87      0.85      0.86       200\n",
      "      390130       0.97      0.97      0.97       200\n",
      "      390140       0.90      0.97      0.93       181\n",
      "      390190       0.89      0.84      0.87       200\n",
      "      390210       0.83      0.83      0.83       200\n",
      "      390220       0.96      0.95      0.95        95\n",
      "      390230       0.85      0.88      0.86       200\n",
      "      390290       0.84      0.90      0.87       192\n",
      "      390311       0.98      0.98      0.98       200\n",
      "      390319       0.90      0.91      0.91        90\n",
      "      390320       0.94      0.97      0.96       200\n",
      "      390330       0.93      0.93      0.93       200\n",
      "      390390       0.92      0.83      0.87       200\n",
      "      390410       0.92      0.98      0.95       186\n",
      "      390421       0.93      0.89      0.91        46\n",
      "      390422       0.88      0.89      0.88        55\n",
      "      390430       0.92      0.94      0.93       163\n",
      "      390440       0.71      0.36      0.48        14\n",
      "      390450       1.00      0.91      0.95        34\n",
      "      390461       0.92      0.92      0.92       182\n",
      "      390469       0.87      0.90      0.89        91\n",
      "      390490       0.93      0.81      0.87        16\n",
      "      390512       1.00      0.71      0.83        21\n",
      "      390519       0.92      0.86      0.89        28\n",
      "      390521       0.81      0.76      0.79        17\n",
      "      390529       0.94      0.95      0.95       123\n",
      "      390530       0.91      0.97      0.94        61\n",
      "      390591       0.85      0.73      0.79        56\n",
      "      390599       0.64      0.74      0.69        47\n",
      "      390610       0.88      0.85      0.87        72\n",
      "      390690       0.71      0.74      0.73       200\n",
      "      390710       0.86      0.94      0.90       200\n",
      "      390720       0.84      0.84      0.84       200\n",
      "      390730       0.89      0.94      0.91       200\n",
      "      390740       0.85      0.92      0.88       200\n",
      "      390750       0.95      0.86      0.90        43\n",
      "      390761       0.97      0.97      0.97       186\n",
      "      390769       0.88      0.93      0.90        71\n",
      "      390770       1.00      0.50      0.67         4\n",
      "      390791       0.86      0.89      0.88        63\n",
      "      390799       0.83      0.78      0.81       200\n",
      "      390810       0.80      0.80      0.80       200\n",
      "      390890       0.74      0.88      0.80       200\n",
      "      390910       0.94      0.95      0.95       103\n",
      "      390920       0.69      0.56      0.62        32\n",
      "      390931       0.77      0.71      0.74        14\n",
      "      390939       0.44      0.67      0.53         6\n",
      "      390940       0.89      0.88      0.88       112\n",
      "      390950       0.77      0.82      0.79       200\n",
      "      391000       0.89      0.93      0.90       200\n",
      "      391110       0.96      0.98      0.97       135\n",
      "      391190       0.83      0.72      0.78       200\n",
      "      391211       0.86      1.00      0.92         6\n",
      "      391212       0.00      0.00      0.00         1\n",
      "      391220       0.93      0.99      0.96        70\n",
      "      391231       0.84      0.96      0.90       200\n",
      "      391239       0.97      0.97      0.97       200\n",
      "      391290       0.92      0.96      0.94       185\n",
      "      391310       0.96      0.88      0.92        26\n",
      "      391390       0.97      0.85      0.91        88\n",
      "      391400       0.89      0.96      0.92       150\n",
      "      391510       0.84      0.75      0.79        28\n",
      "      391520       0.83      0.91      0.87        11\n",
      "      391530       0.98      0.97      0.98       115\n",
      "      391590       0.86      0.96      0.91       200\n",
      "      391610       0.69      0.59      0.64        37\n",
      "      391620       0.85      0.84      0.85       200\n",
      "      391690       0.76      0.75      0.75       182\n",
      "      391710       0.94      0.93      0.94       123\n",
      "      391721       0.75      0.63      0.69        57\n",
      "      391722       0.86      0.96      0.91       200\n",
      "      391723       0.92      0.74      0.82        88\n",
      "      391729       0.62      0.62      0.62        91\n",
      "      391731       0.74      0.68      0.71       103\n",
      "      391732       0.66      0.69      0.68       200\n",
      "      391733       0.54      0.68      0.60        74\n",
      "      391739       0.66      0.67      0.66       200\n",
      "      391740       0.83      0.78      0.80       200\n",
      "      391810       0.87      0.94      0.91       200\n",
      "      391890       0.87      0.90      0.88       200\n",
      "      391910       0.83      0.79      0.81       200\n",
      "      391990       0.70      0.68      0.69       200\n",
      "      392010       0.81      0.73      0.77       200\n",
      "      392020       0.85      0.86      0.86       200\n",
      "      392030       0.86      0.93      0.89       200\n",
      "      392043       0.90      0.89      0.90       194\n",
      "      392049       0.83      0.84      0.83       174\n",
      "      392051       0.87      0.91      0.89       152\n",
      "      392059       0.80      0.84      0.82        44\n",
      "      392061       0.88      0.78      0.83        78\n",
      "      392062       0.84      0.81      0.83       200\n",
      "      392063       0.86      0.43      0.57        14\n",
      "      392069       0.91      0.71      0.80        55\n",
      "      392071       0.86      1.00      0.93        25\n",
      "      392073       1.00      0.60      0.75        15\n",
      "      392079       0.80      0.71      0.75        28\n",
      "      392091       0.97      0.97      0.97        67\n",
      "      392092       0.84      0.87      0.86        31\n",
      "      392093       0.50      0.67      0.57         3\n",
      "      392094       0.80      0.57      0.67         7\n",
      "      392099       0.87      0.79      0.83       141\n",
      "      392111       0.72      0.77      0.74        30\n",
      "      392112       0.91      0.85      0.88       200\n",
      "      392113       0.77      0.77      0.77       200\n",
      "      392114       0.77      0.97      0.86        78\n",
      "      392119       0.86      0.82      0.84       200\n",
      "      392190       0.75      0.69      0.72       200\n",
      "      392210       0.93      0.96      0.95       200\n",
      "      392220       0.75      0.88      0.81       200\n",
      "      392290       0.94      0.96      0.95       200\n",
      "      392310       0.73      0.78      0.75       200\n",
      "      392321       0.76      0.79      0.78       200\n",
      "      392329       0.74      0.76      0.75       200\n",
      "      392330       0.81      0.83      0.82       200\n",
      "      392340       0.86      0.90      0.88       200\n",
      "      392350       0.76      0.77      0.76       200\n",
      "      392390       0.71      0.69      0.70       200\n",
      "      392410       0.65      0.68      0.66       200\n",
      "      392490       0.68      0.56      0.61       200\n",
      "      392510       0.93      0.84      0.88        89\n",
      "      392520       0.83      0.91      0.87       200\n",
      "      392530       0.94      0.94      0.94       200\n",
      "      392590       0.89      0.79      0.84       200\n",
      "      392610       0.92      0.87      0.89       200\n",
      "      392620       0.82      0.77      0.80       200\n",
      "      392630       0.63      0.79      0.70       200\n",
      "      392640       0.65      0.72      0.68       200\n",
      "      392690       0.39      0.26      0.31       200\n",
      "      400110       0.93      0.93      0.93       122\n",
      "      400121       0.83      0.81      0.82       200\n",
      "      400122       0.91      0.84      0.88       200\n",
      "      400129       0.77      0.75      0.76        48\n",
      "      400130       1.00      1.00      1.00        13\n",
      "      400211       0.91      0.97      0.94        99\n",
      "      400219       0.94      0.94      0.94       200\n",
      "      400220       0.92      0.81      0.86       200\n",
      "      400231       0.85      0.85      0.85        20\n",
      "      400239       0.94      0.94      0.94        51\n",
      "      400241       0.97      0.98      0.98       190\n",
      "      400249       0.75      1.00      0.86        15\n",
      "      400251       0.90      0.99      0.95       200\n",
      "      400259       0.98      0.93      0.95        99\n",
      "      400260       0.96      0.96      0.96       157\n",
      "      400270       0.95      0.98      0.96       189\n",
      "      400280       0.92      0.52      0.67        21\n",
      "      400291       0.93      0.96      0.94       194\n",
      "      400299       0.78      0.60      0.68        53\n",
      "      400300       0.97      0.98      0.97       174\n",
      "      400400       0.94      0.89      0.92        57\n",
      "      400510       0.89      0.89      0.89       150\n",
      "      400520       0.82      1.00      0.90         9\n",
      "      400591       0.76      0.72      0.74        43\n",
      "      400599       0.96      0.88      0.92       117\n",
      "      400610       0.84      0.88      0.86       200\n",
      "      400690       0.92      0.58      0.71        19\n",
      "      400700       0.93      0.98      0.96       200\n",
      "      400811       0.72      0.84      0.77        69\n",
      "      400819       0.86      0.52      0.65        23\n",
      "      400821       0.79      0.79      0.79       139\n",
      "      400829       0.58      0.50      0.54        52\n",
      "      400911       0.62      0.42      0.51        59\n",
      "      400912       0.72      0.60      0.66        35\n",
      "      400921       0.78      0.90      0.83       200\n",
      "      400922       0.72      0.57      0.64        49\n",
      "      400931       0.77      0.63      0.69       182\n",
      "      400932       0.74      0.74      0.74        50\n",
      "      400941       0.89      0.90      0.90       161\n",
      "      400942       0.59      0.54      0.56        81\n",
      "      401011       0.83      0.83      0.83        29\n",
      "      401012       0.89      0.74      0.81       124\n",
      "      401019       0.93      0.94      0.94       200\n",
      "      401031       0.74      0.76      0.75        59\n",
      "      401032       0.73      0.53      0.61        36\n",
      "      401033       0.95      0.90      0.92        97\n",
      "      401034       0.93      0.87      0.90        31\n",
      "      401035       0.89      0.76      0.82        66\n",
      "      401036       0.90      0.75      0.82        24\n",
      "      401039       0.81      0.82      0.81       132\n",
      "      401110       0.80      0.82      0.81       200\n",
      "      401120       0.84      0.82      0.83       200\n",
      "      401130       0.92      0.93      0.92        72\n",
      "      401140       0.89      0.95      0.92       200\n",
      "      401150       0.84      0.86      0.85        36\n",
      "      401170       0.81      0.91      0.86       200\n",
      "      401180       0.81      0.77      0.79       200\n",
      "      401190       0.90      0.89      0.89       200\n",
      "      401211       0.93      0.93      0.93       100\n",
      "      401212       0.95      0.97      0.96       200\n",
      "      401213       0.96      0.89      0.92        55\n",
      "      401219       0.90      0.86      0.88        51\n",
      "      401220       0.94      0.93      0.93       200\n",
      "      401290       0.92      0.91      0.91       200\n",
      "      401310       0.94      0.92      0.93       115\n",
      "      401320       0.96      0.96      0.96       200\n",
      "      401390       0.93      0.88      0.90       176\n",
      "      401410       0.97      0.87      0.92        38\n",
      "      401490       1.00      0.74      0.85        31\n",
      "      401511       0.91      0.92      0.92       139\n",
      "      401519       0.89      0.92      0.91       200\n",
      "      401590       0.97      0.93      0.95       100\n",
      "      401610       0.75      0.89      0.81       200\n",
      "      401691       0.88      0.94      0.91       200\n",
      "      401692       0.92      0.97      0.94       135\n",
      "      401693       0.79      0.79      0.79       200\n",
      "      401694       1.00      0.60      0.75         5\n",
      "      401695       0.96      0.94      0.95       200\n",
      "      401699       0.67      0.58      0.62       200\n",
      "      401700       0.85      0.76      0.80        59\n",
      "\n",
      "    accuracy                           0.85     26849\n",
      "   macro avg       0.84      0.82      0.83     26849\n",
      "weighted avg       0.85      0.85      0.85     26849\n",
      "\n",
      "[[178   7   1 ...   0   1   0]\n",
      " [ 10 170   0 ...   0   0   0]\n",
      " [  0   0 195 ...   0   0   0]\n",
      " ...\n",
      " [  1   0   0 ... 189   1   0]\n",
      " [  0   1   0 ...   0 116   2]\n",
      " [  0   0   0 ...   0   0  45]]\n",
      "Created predictions in 6.769 seconds\n"
     ]
    }
   ],
   "source": [
    "trial12 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "    ('classifier', RandomForestClassifier()),\n",
    "])\n",
    " \n",
    "acc = train(trial12, X_train['Desc'], y_train, X_dev['Desc'], y_dev, 'saved_models/RF_tfidf_model.sav')\n",
    "\n",
    "results.at['RF-tfidf Desc','Accuracy'] = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-identification",
   "metadata": {},
   "source": [
    "### Reload models, generate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "spread-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
    "\n",
    "def load_model(filename):\n",
    "    loaded = pickle.load(open(filename, 'rb'))\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mineral-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bow_mod = load_model('saved_models/NB_BOW_model.sav')\n",
    "results.at['NB-BOW Desc','Accuracy'] = nb_bow_mod.score(X_dev['Desc'], y_dev)\n",
    "\n",
    "nb_tfidf_mod = load_model('saved_models/NB_tfidf_model.sav')\n",
    "results.at['NB-tfidf Desc','Accuracy'] = nb_tfidf_mod.score(X_dev['Desc'], y_dev)\n",
    "\n",
    "knn_bow_mod = load_model('saved_models/KNN_BOW_model.sav')\n",
    "results.at['KNN-BOW Desc','Accuracy'] = knn_bow_mod.score(X_dev['Desc'], y_dev)\n",
    "\n",
    "knn_tfidf_mod = load_model('saved_models/KNN_tfidf_model.sav')\n",
    "results.at['KNN-tfidf Desc','Accuracy'] = knn_tfidf_mod.score(X_dev['Desc'], y_dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "finite-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow_mod = load_model('saved_models/LogReg_BOW_model.sav')\n",
    "results.at['LogReg-BOW Desc','Accuracy'] = lr_bow_mod.score(X_dev['Desc'], y_dev)\n",
    "\n",
    "lr_tfidf_mod = load_model('saved_models/LogReg_tfidf_model.sav')\n",
    "results.at['LogReg-tfidf Desc','Accuracy'] = lr_tfidf_mod.score(X_dev['Desc'], y_dev)\n",
    "\n",
    "rf_bow_mod = load_model('saved_models/RF_BOW_model.sav')\n",
    "results.at['RF-BOW Desc','Accuracy'] = rf_bow_mod.score(X_dev['Desc'], y_dev)\n",
    "\n",
    "rf_tfidf_mod = load_model('saved_models/RF_tfidf_model.sav')\n",
    "results.at['RF-tfidf Desc','Accuracy'] = rf_tfidf_mod.score(X_dev['Desc'], y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "multiple-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bow_mod = load_model('saved_models/XGB_BOW_model.sav')\n",
    "results.at['XGBoost-BOW Desc','Accuracy'] = xgb_bow_mod.score(X_dev['Desc'], y_dev)\n",
    "\n",
    "xgb_tfidf_mod = load_model('saved_models/XGB_tfidf_model.sav')\n",
    "results.at['XGBoost-tfidf Desc','Accuracy'] = xgb_tfidf_mod.score(X_dev['Desc'], y_dev)\n",
    "\n",
    "svm_bow_mod = load_model('saved_models/SVM_BOW_model.sav')\n",
    "results.at['SVM-BOW Desc','Accuracy'] = svm_bow_mod.score(X_dev['Desc'], y_dev)\n",
    "\n",
    "svm_tfidf_mod = load_model('saved_models/SVM_tfidf_model.sav')\n",
    "results.at['SVM-tfidf Desc','Accuracy'] = svm_tfidf_mod.score(X_dev['Desc'], y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pleased-adobe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.007458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB-BOW Desc</th>\n",
       "      <td>0.653581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB-tfidf Desc</th>\n",
       "      <td>0.688406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN-BOW Desc</th>\n",
       "      <td>0.750605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN-tfidf Desc</th>\n",
       "      <td>0.760512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg-BOW Desc</th>\n",
       "      <td>0.832061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg-tfidf Desc</th>\n",
       "      <td>0.801557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM-BOW Desc</th>\n",
       "      <td>0.457149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM-tfidf Desc</th>\n",
       "      <td>0.834668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost-BOW Desc</th>\n",
       "      <td>0.829081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost-tfidf Desc</th>\n",
       "      <td>0.817759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF-BOW Desc</th>\n",
       "      <td>0.84465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF-tfidf Desc</th>\n",
       "      <td>0.849976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Accuracy\n",
       "Baseline            0.007458\n",
       "NB-BOW Desc         0.653581\n",
       "NB-tfidf Desc       0.688406\n",
       "KNN-BOW Desc        0.750605\n",
       "KNN-tfidf Desc      0.760512\n",
       "LogReg-BOW Desc     0.832061\n",
       "LogReg-tfidf Desc   0.801557\n",
       "SVM-BOW Desc        0.457149\n",
       "SVM-tfidf Desc      0.834668\n",
       "XGBoost-BOW Desc    0.829081\n",
       "XGBoost-tfidf Desc  0.817759\n",
       "RF-BOW Desc          0.84465\n",
       "RF-tfidf Desc       0.849976"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sporting-czech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Model Comparison, Chapters 39 & 40')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.barplot(x=results.index, y=results[\"Accuracy\"])\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=75)\n",
    "plt.title(\"Model Comparison, Chapters 39 & 40\", size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "innovative-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('ModelResults_Chp39_40_'+ '03022021' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-exclusion",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Work with the BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'knn' : KNeighborsClassifier(), 'logit' : LogisticRegression(), 'svm': SVC()\n",
    "}\n",
    "\n",
    "for model, call in models.items():\n",
    "    print(f'Training {model}')\n",
    "    call.fit(X_train['BERT_Product Desc'], y_train)\n",
    "    pred = call.predict(X_dev['BERT_Product Desc'], y_dev)\n",
    "    print(accuracy_score(y_dev, pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-emphasis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
