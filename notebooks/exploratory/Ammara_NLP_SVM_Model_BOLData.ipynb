{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "synthetic-language",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "emotional-puzzle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import dask.dataframe as ddf\n",
    "from math import nan\n",
    "import panel as pn\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import seaborn as sns\n",
    "import plotly as pty\n",
    "import plotly.express as px\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infrared-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opposite-trust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_87128714.parq\n"
     ]
    }
   ],
   "source": [
    "!ls /data/common/trade_data/2019/data_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fluid-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_parq = dd.read_parquet('/data/common/trade_data/2019/data_samples/sample_87128714.parq', engine='fastparquet', chunksize=\"100MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "breeding-guarantee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7269"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_df_parq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "numeric-christian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n"
     ]
    }
   ],
   "source": [
    "sampled_df = sample_df_parq.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "strong-bidder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System Identity Id</th>\n",
       "      <th>Estimate Arrival Date</th>\n",
       "      <th>Actual Arrival Date</th>\n",
       "      <th>Bill of Lading</th>\n",
       "      <th>Master Bill of Lading</th>\n",
       "      <th>Bill Type Code</th>\n",
       "      <th>Carrier SASC Code</th>\n",
       "      <th>Vessel Country Code</th>\n",
       "      <th>Vessel Code</th>\n",
       "      <th>Vessel Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Product Desc</th>\n",
       "      <th>Marks &amp; Numbers</th>\n",
       "      <th>HS Code Sure Level</th>\n",
       "      <th>CIF</th>\n",
       "      <th>Indicator of true supplier</th>\n",
       "      <th>Indicator of true buyer</th>\n",
       "      <th>END</th>\n",
       "      <th>HS Code</th>\n",
       "      <th>HS_Code</th>\n",
       "      <th>Merged_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6003201907090000254809</td>\n",
       "      <td>20190705</td>\n",
       "      <td>20190705</td>\n",
       "      <td>CHSLTPE19060165</td>\n",
       "      <td>EGLV003901609611</td>\n",
       "      <td>H</td>\n",
       "      <td>CHSL, CHISLEY MOTOR COACHES</td>\n",
       "      <td>PA</td>\n",
       "      <td>9306990</td>\n",
       "      <td>OOCL VANCOUVER</td>\n",
       "      <td>...</td>\n",
       "      <td>ELLIPTICAL TRAINER,TREADMILL, ESCALATE&lt;br/&gt;</td>\n",
       "      <td>NO MARKS&lt;br/&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>END</td>\n",
       "      <td>871200</td>\n",
       "      <td>871200</td>\n",
       "      <td>Bicycles and other cycles (including delivery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6003201901040000381477</td>\n",
       "      <td>20181230</td>\n",
       "      <td>20190103</td>\n",
       "      <td>AMAWSHNGBA807064</td>\n",
       "      <td>APLUNPFB000624</td>\n",
       "      <td>H</td>\n",
       "      <td>AMAW</td>\n",
       "      <td>CN</td>\n",
       "      <td>APL BARCELONA</td>\n",
       "      <td>APL BARCELONA</td>\n",
       "      <td>...</td>\n",
       "      <td>SCH 830 TREADMILL&lt;br/&gt;</td>\n",
       "      <td>AS ADDRESSED&lt;br/&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>END</td>\n",
       "      <td>871200</td>\n",
       "      <td>871200</td>\n",
       "      <td>Bicycles and other cycles (including delivery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6003201904300000373799</td>\n",
       "      <td>20190425</td>\n",
       "      <td>20190429</td>\n",
       "      <td>SFOKNGB19040368</td>\n",
       "      <td>OOLU2106406710</td>\n",
       "      <td>H</td>\n",
       "      <td>SFOK</td>\n",
       "      <td>PA</td>\n",
       "      <td>9168855</td>\n",
       "      <td>EVER URANUS</td>\n",
       "      <td>...</td>\n",
       "      <td>FITNESSMACHINE; TREADMILL&lt;br/&gt;</td>\n",
       "      <td>NO MARKS&lt;br/&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>END</td>\n",
       "      <td>871200</td>\n",
       "      <td>871200</td>\n",
       "      <td>Bicycles and other cycles (including delivery ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       System Identity Id  Estimate Arrival Date  Actual Arrival Date  \\\n",
       "0  6003201907090000254809               20190705             20190705   \n",
       "1  6003201901040000381477               20181230             20190103   \n",
       "2  6003201904300000373799               20190425             20190429   \n",
       "\n",
       "     Bill of Lading Master Bill of Lading Bill Type Code  \\\n",
       "0   CHSLTPE19060165      EGLV003901609611              H   \n",
       "1  AMAWSHNGBA807064        APLUNPFB000624              H   \n",
       "2   SFOKNGB19040368        OOLU2106406710              H   \n",
       "\n",
       "             Carrier SASC Code Vessel Country Code    Vessel Code  \\\n",
       "0  CHSL, CHISLEY MOTOR COACHES                  PA        9306990   \n",
       "1                         AMAW                  CN  APL BARCELONA   \n",
       "2                         SFOK                  PA        9168855   \n",
       "\n",
       "      Vessel Name  ...                                 Product Desc  \\\n",
       "0  OOCL VANCOUVER  ...  ELLIPTICAL TRAINER,TREADMILL, ESCALATE<br/>   \n",
       "1   APL BARCELONA  ...                       SCH 830 TREADMILL<br/>   \n",
       "2     EVER URANUS  ...               FITNESSMACHINE; TREADMILL<br/>   \n",
       "\n",
       "     Marks & Numbers  HS Code Sure Level  CIF Indicator of true supplier  \\\n",
       "0      NO MARKS<br/>                   5  0.0                          Y   \n",
       "1  AS ADDRESSED<br/>                   5  0.0                          Y   \n",
       "2      NO MARKS<br/>                   5  0.0                          Y   \n",
       "\n",
       "  Indicator of true buyer  END HS Code HS_Code  \\\n",
       "0                       Y  END  871200  871200   \n",
       "1                       Y  END  871200  871200   \n",
       "2                       Y  END  871200  871200   \n",
       "\n",
       "                                  Merged_Description  \n",
       "0  Bicycles and other cycles (including delivery ...  \n",
       "1  Bicycles and other cycles (including delivery ...  \n",
       "2  Bicycles and other cycles (including delivery ...  \n",
       "\n",
       "[3 rows x 70 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "focal-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG ['871200' '871410' '871420' '871491' '871492' '871493' '871494' '871495'\n",
      " '871496' '871499']\n"
     ]
    }
   ],
   "source": [
    "random_seed = 1\n",
    "all_classes = sampled_df.HS_Code.unique()\n",
    "print('DEBUG', all_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adequate-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = sampled_df[['HS_Code', 'Product Desc', 'Merged_Description']].rename({'HS_Code' : 'label', 'Product Desc' : 'text'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "partial-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>Merged_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>871200</td>\n",
       "      <td>ELLIPTICAL TRAINER,TREADMILL, ESCALATE&lt;br/&gt;</td>\n",
       "      <td>Bicycles and other cycles (including delivery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>871200</td>\n",
       "      <td>SCH 830 TREADMILL&lt;br/&gt;</td>\n",
       "      <td>Bicycles and other cycles (including delivery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>871200</td>\n",
       "      <td>FITNESSMACHINE; TREADMILL&lt;br/&gt;</td>\n",
       "      <td>Bicycles and other cycles (including delivery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>871200</td>\n",
       "      <td>COMPLETE BICYCLES &amp; BICYCLE PARTS &amp; ELECTRIC B...</td>\n",
       "      <td>Bicycles and other cycles (including delivery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>871200</td>\n",
       "      <td>LOUISIANA GRILLS LG900 W FRONT SHELF&lt;br/&gt;</td>\n",
       "      <td>Bicycles and other cycles (including delivery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>871499</td>\n",
       "      <td>HANDLEBAR/SEATPOST BICYCLE PARTS&lt;br/&gt;</td>\n",
       "      <td>Parts and accessories of vehicles of headings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>871499</td>\n",
       "      <td>SHIPPER S LOAD, COUNT &amp; SEAL (74P KGS) CY / CY...</td>\n",
       "      <td>Parts and accessories of vehicles of headings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>871499</td>\n",
       "      <td>BICYCLE ACCESSORIES BC SEAT PAD GELCORE REG WS...</td>\n",
       "      <td>Parts and accessories of vehicles of headings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>871499</td>\n",
       "      <td>ROTOR &amp; WING&lt;br/&gt;</td>\n",
       "      <td>Parts and accessories of vehicles of headings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7268</th>\n",
       "      <td>871499</td>\n",
       "      <td>BICYCLE PARTS HS CODE:8714.99 AMS#PSLAP1902 10...</td>\n",
       "      <td>Parts and accessories of vehicles of headings ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7269 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "0     871200        ELLIPTICAL TRAINER,TREADMILL, ESCALATE<br/>   \n",
       "1     871200                             SCH 830 TREADMILL<br/>   \n",
       "2     871200                     FITNESSMACHINE; TREADMILL<br/>   \n",
       "3     871200  COMPLETE BICYCLES & BICYCLE PARTS & ELECTRIC B...   \n",
       "4     871200          LOUISIANA GRILLS LG900 W FRONT SHELF<br/>   \n",
       "...      ...                                                ...   \n",
       "7264  871499              HANDLEBAR/SEATPOST BICYCLE PARTS<br/>   \n",
       "7265  871499  SHIPPER S LOAD, COUNT & SEAL (74P KGS) CY / CY...   \n",
       "7266  871499  BICYCLE ACCESSORIES BC SEAT PAD GELCORE REG WS...   \n",
       "7267  871499                                  ROTOR & WING<br/>   \n",
       "7268  871499  BICYCLE PARTS HS CODE:8714.99 AMS#PSLAP1902 10...   \n",
       "\n",
       "                                     Merged_Description  \n",
       "0     Bicycles and other cycles (including delivery ...  \n",
       "1     Bicycles and other cycles (including delivery ...  \n",
       "2     Bicycles and other cycles (including delivery ...  \n",
       "3     Bicycles and other cycles (including delivery ...  \n",
       "4     Bicycles and other cycles (including delivery ...  \n",
       "...                                                 ...  \n",
       "7264  Parts and accessories of vehicles of headings ...  \n",
       "7265  Parts and accessories of vehicles of headings ...  \n",
       "7266  Parts and accessories of vehicles of headings ...  \n",
       "7267  Parts and accessories of vehicles of headings ...  \n",
       "7268  Parts and accessories of vehicles of headings ...  \n",
       "\n",
       "[7269 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "twenty-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - a : Remove blank rows if any.\n",
    "sampled_df['text'].dropna(inplace=True)\n",
    "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "sampled_df['text'] = [entry.lower() for entry in sampled_df['text']]\n",
    "sampled_df['Merged_Description'] = [entry.lower() for entry in sampled_df['Merged_Description']]\n",
    "sampled_df['text'] = [entry.replace('<br/>', '') for entry in sampled_df['text']]\n",
    "\n",
    "# # Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "sampled_df['text']= [word_tokenize(entry) for entry in sampled_df['text']]\n",
    "sampled_df['Merged_Description']= [word_tokenize(entry) for entry in sampled_df['Merged_Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "failing-preference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df['text'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dying-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(sampled_df['text']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "#             Final_words.append(word) # No Lemmatization\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "\n",
    "    # The final processed set of words for each iteration will be stored in 'Merged_final'\n",
    "    sampled_df.loc[index,'text_final'] = str(Final_words)\n",
    "    \n",
    "# for index,entry in enumerate(sampled_df['Merged_Description']):\n",
    "#     # Declaring Empty List to store the words that follow the rules for this step\n",
    "#     Final_words = []\n",
    "#     # Initializing WordNetLemmatizer()\n",
    "#     word_Lemmatized = WordNetLemmatizer()\n",
    "#     # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "#     for word, tag in pos_tag(entry):\n",
    "#         # Below condition is to check for Stop words and consider only alphabets\n",
    "#         if word not in stopwords.words('english') and word.isalpha():\n",
    "#             word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "#             Final_words.append(word_Final)\n",
    "#     # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "#     sampled_df.loc[index,'Merged_final'] = str(Final_words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mighty-russell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871200 700 300\n",
      "871410 554 238\n",
      "871420 700 300\n",
      "871491 221 95\n",
      "871492 700 300\n",
      "871493 700 300\n",
      "871494 510 219\n",
      "871495 43 19\n",
      "871496 259 111\n",
      "871499 700 300\n"
     ]
    }
   ],
   "source": [
    "for c in all_classes :\n",
    "    df = sampled_df[sampled_df.label == c]\n",
    "    Train_X, Val_X, Train_Y, Val_Y = model_selection.train_test_split(df['text_final'],df['label'],test_size=0.3)\n",
    "    print(c,len(Train_X), len(Val_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "floral-olive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871200 700 300\n",
      "871200 700 700 300 300\n",
      "871410 554 238\n",
      "871410 1254 1254 538 538\n",
      "871420 700 300\n",
      "871420 1954 1954 838 838\n",
      "871491 221 95\n",
      "871491 2175 2175 933 933\n",
      "871492 700 300\n",
      "871492 2875 2875 1233 1233\n",
      "871493 700 300\n",
      "871493 3575 3575 1533 1533\n",
      "871494 510 219\n",
      "871494 4085 4085 1752 1752\n",
      "871495 43 19\n",
      "871495 4128 4128 1771 1771\n",
      "871496 259 111\n",
      "871496 4387 4387 1882 1882\n",
      "871499 700 300\n",
      "871499 5087 5087 2182 2182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-ec632ac48f11>:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  Train_X, Val_X, Train_Y, Val_Y = pd.Series() , pd.Series() , pd.Series() , pd.Series()\n"
     ]
    }
   ],
   "source": [
    "Train_X, Val_X, Train_Y, Val_Y = pd.Series() , pd.Series() , pd.Series() , pd.Series()\n",
    "for c in all_classes :\n",
    "    df = sampled_df[sampled_df.label == c]\n",
    "    T_X, V_X, T_Y, V_Y = model_selection.train_test_split(df['text_final'],df['label'],test_size=0.3)\n",
    "    print(c,len(T_X), len(V_X))\n",
    "    Train_X = Train_X.append(T_X, ignore_index=True)\n",
    "    Train_Y = Train_Y.append(T_Y, ignore_index=True)\n",
    "    Val_X = Val_X.append(V_X, ignore_index=True)\n",
    "    Val_Y = Val_Y.append(V_Y, ignore_index=True)\n",
    "    print(c,len(Train_X), len(Train_Y),len(Val_X), len(Val_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "czech-society",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_X) + len(Val_X) == len(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "liberal-allowance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['871200', '871410', '871420', '871491', '871492', '871493',\n",
       "       '871494', '871495', '871496', '871499'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "determined-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['871200', '871410', '871420', '871491', '871492', '871493',\n",
       "       '871494', '871495', '871496', '871499'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Val_Y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "future-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Val_Y = Encoder.fit_transform(Val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "painful-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5296\n"
     ]
    }
   ],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=10000)\n",
    "Tfidf_vect.fit(sampled_df['text_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Val_X_Tfidf = Tfidf_vect.transform(Val_X)\n",
    "print(len(Tfidf_vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "therapeutic-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  81.02658111824014\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Val_X_Tfidf)\n",
    "\n",
    "# Metrics\n",
    "print(\"Naive Bayes Accuracy Score -> \", accuracy_score(predictions_NB, Val_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "written-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      871200       0.70      0.85      0.77       300\n",
      "      871410       0.81      0.89      0.85       238\n",
      "      871420       0.84      0.87      0.85       300\n",
      "      871491       1.00      0.35      0.52        95\n",
      "      871492       0.88      0.87      0.87       300\n",
      "      871493       0.82      0.91      0.86       300\n",
      "      871494       0.94      0.77      0.84       219\n",
      "      871495       0.00      0.00      0.00        19\n",
      "      871496       1.00      0.52      0.69       111\n",
      "      871499       0.71      0.83      0.77       300\n",
      "\n",
      "    accuracy                           0.81      2182\n",
      "   macro avg       0.77      0.69      0.70      2182\n",
      "weighted avg       0.82      0.81      0.80      2182\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Val_Y,predictions_NB, target_names=sampled_df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "announced-diversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  84.2346471127406\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', decision_function_shape='ovo')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Val_X_Tfidf)\n",
    "\n",
    "# Metrics\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Val_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "applied-hartford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      871200       0.78      0.84      0.81       300\n",
      "      871410       0.84      0.88      0.86       238\n",
      "      871420       0.77      0.90      0.83       300\n",
      "      871491       0.79      0.57      0.66        95\n",
      "      871492       0.92      0.89      0.91       300\n",
      "      871493       0.95      0.89      0.92       300\n",
      "      871494       0.89      0.84      0.86       219\n",
      "      871495       0.75      0.32      0.44        19\n",
      "      871496       0.98      0.75      0.85       111\n",
      "      871499       0.76      0.81      0.79       300\n",
      "\n",
      "    accuracy                           0.84      2182\n",
      "   macro avg       0.84      0.77      0.79      2182\n",
      "weighted avg       0.85      0.84      0.84      2182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Val_Y,predictions_SVM, target_names=sampled_df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "falling-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train on merged description but predict on item description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-loading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "neural-tower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "[CV 1/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   1.6s\n",
      "[CV 2/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   1.6s\n",
      "[CV 3/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   1.6s\n",
      "[CV 4/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   1.6s\n",
      "[CV 5/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   1.6s\n",
      "[CV 1/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=   1.5s\n",
      "[CV 2/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=   1.5s\n",
      "[CV 3/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=   1.5s\n",
      "[CV 4/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=   1.5s\n",
      "[CV 5/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=   1.5s\n",
      "[CV 1/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   1.5s\n",
      "[CV 2/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   1.6s\n",
      "[CV 3/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   1.5s\n",
      "[CV 4/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   1.5s\n",
      "[CV 5/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   1.6s\n",
      "[CV 1/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=   1.6s\n",
      "[CV 2/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=   1.6s\n",
      "[CV 3/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=   1.6s\n",
      "[CV 4/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=   1.6s\n",
      "[CV 5/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=   1.6s\n",
      "[CV 1/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   1.1s\n",
      "[CV 2/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   1.1s\n",
      "[CV 3/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   1.1s\n",
      "[CV 4/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   1.1s\n",
      "[CV 5/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   1.1s\n",
      "[CV 1/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=   1.5s\n",
      "[CV 2/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=   1.6s\n",
      "[CV 3/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=   1.5s\n",
      "[CV 4/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=   1.5s\n",
      "[CV 5/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=   1.6s\n",
      "[CV 1/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=   1.0s\n",
      "[CV 2/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=   1.0s\n",
      "[CV 3/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=   1.0s\n",
      "[CV 4/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=   1.0s\n",
      "[CV 5/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=   1.0s\n",
      "[CV 1/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=   1.1s\n",
      "[CV 2/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=   1.1s\n",
      "[CV 3/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=   1.1s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=   1.1s\n",
      "[CV 5/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=   1.1s\n",
      "[CV 1/5] END ...........................C=0.1, kernel=linear; total time=   1.1s\n",
      "[CV 2/5] END ...........................C=0.1, kernel=linear; total time=   1.1s\n",
      "[CV 3/5] END ...........................C=0.1, kernel=linear; total time=   1.1s\n",
      "[CV 4/5] END ...........................C=0.1, kernel=linear; total time=   1.1s\n",
      "[CV 5/5] END ...........................C=0.1, kernel=linear; total time=   1.1s\n",
      "[CV 1/5] END .............................C=1, kernel=linear; total time=   0.8s\n",
      "[CV 2/5] END .............................C=1, kernel=linear; total time=   0.8s\n",
      "[CV 3/5] END .............................C=1, kernel=linear; total time=   0.8s\n",
      "[CV 4/5] END .............................C=1, kernel=linear; total time=   0.8s\n",
      "[CV 5/5] END .............................C=1, kernel=linear; total time=   0.8s\n",
      "[CV 1/5] END ............................C=10, kernel=linear; total time=   0.8s\n",
      "[CV 2/5] END ............................C=10, kernel=linear; total time=   0.8s\n",
      "[CV 3/5] END ............................C=10, kernel=linear; total time=   0.8s\n",
      "[CV 4/5] END ............................C=10, kernel=linear; total time=   0.8s\n",
      "[CV 5/5] END ............................C=10, kernel=linear; total time=   0.8s\n",
      "[CV 1/5] END ...........................C=100, kernel=linear; total time=   0.7s\n",
      "[CV 2/5] END ...........................C=100, kernel=linear; total time=   0.7s\n",
      "[CV 3/5] END ...........................C=100, kernel=linear; total time=   0.7s\n",
      "[CV 4/5] END ...........................C=100, kernel=linear; total time=   0.7s\n",
      "[CV 5/5] END ...........................C=100, kernel=linear; total time=   0.7s\n",
      "[CV 1/5] END ..........................C=1000, kernel=linear; total time=   1.1s\n",
      "[CV 2/5] END ..........................C=1000, kernel=linear; total time=   0.9s\n",
      "[CV 3/5] END ..........................C=1000, kernel=linear; total time=   0.9s\n",
      "[CV 4/5] END ..........................C=1000, kernel=linear; total time=   0.9s\n",
      "[CV 5/5] END ..........................C=1000, kernel=linear; total time=   0.9s\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "SVC(C=1000, decision_function_shape='ovo', gamma=0.001)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "  \n",
    "# defining parameter range \n",
    "param_grid = [\n",
    "              {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "              {'C': [0.1, 1, 10, 100, 1000],'kernel': ['linear']}\n",
    "             ]\n",
    "  \n",
    "grid = GridSearchCV(svm.SVC(decision_function_shape='ovo'), param_grid, refit = True, verbose = 3) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "charitable-breakdown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  84.6929422548121\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1000, kernel='rbf', decision_function_shape='ovo', gamma=0.001)\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Val_X_Tfidf)\n",
    "\n",
    "# Metrics\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Val_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "imposed-chancellor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      871200       0.81      0.85      0.83       300\n",
      "      871410       0.86      0.86      0.86       238\n",
      "      871420       0.77      0.90      0.83       300\n",
      "      871491       0.81      0.60      0.69        95\n",
      "      871492       0.92      0.89      0.90       300\n",
      "      871493       0.93      0.90      0.91       300\n",
      "      871494       0.88      0.84      0.86       219\n",
      "      871495       0.82      0.47      0.60        19\n",
      "      871496       0.99      0.77      0.86       111\n",
      "      871499       0.77      0.83      0.80       300\n",
      "\n",
      "    accuracy                           0.85      2182\n",
      "   macro avg       0.86      0.79      0.81      2182\n",
      "weighted avg       0.85      0.85      0.85      2182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Val_Y,predictions_SVM, target_names=sampled_df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "upper-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n"
     ]
    }
   ],
   "source": [
    "!whoami"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
